{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "torch.set_printoptions(sci_mode = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "reddit_df = pd.read_csv(\"../data/Reddit_Data.csv\")\n",
    "twitter_df = pd.read_csv(\"../data/Twitter_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0   family mormon have never tried explain them t...         1\n",
       "1  buddhism has very much lot compatible with chr...         1\n",
       "2  seriously don say thing first all they won get...        -1\n",
       "3  what you have learned yours and only yours wha...         0\n",
       "4  for your own benefit you may want read living ...         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect Reddit data\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect Twitter data\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of NaN columns\n",
    "reddit_df = reddit_df.dropna()\n",
    "twitter_df = twitter_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of comments\n",
    "comments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reddit_df)):\n",
    "    comments.append(str(reddit_df.iloc[i][0]).lower())\n",
    "    \n",
    "for i in range(len(twitter_df)):\n",
    "    comments.append(str(twitter_df.iloc[i][0]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200118"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where all the words will stay\n",
    "all_words = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for string in comments:\n",
    "    all_words += string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurences of each word\n",
    "all_words = all_words.split(\" \")\n",
    "count_words = Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the most common\n",
    "total_words = len(all_words)\n",
    "sorted_words = count_words.most_common(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'': 17229,\n",
       "         'family': 3148,\n",
       "         'mormon': 1,\n",
       "         'have': 27635,\n",
       "         'never': 5040,\n",
       "         'tried': 711,\n",
       "         'explain': 477,\n",
       "         'them': 8119,\n",
       "         'they': 22596,\n",
       "         'still': 4349,\n",
       "         'stare': 8,\n",
       "         'puzzled': 5,\n",
       "         'from': 21034,\n",
       "         'time': 8988,\n",
       "         'like': 17373,\n",
       "         'some': 6863,\n",
       "         'kind': 1408,\n",
       "         'strange': 108,\n",
       "         'creature': 24,\n",
       "         'nonetheless': 19,\n",
       "         'come': 4627,\n",
       "         'admire': 105,\n",
       "         'for': 64714,\n",
       "         'the': 159020,\n",
       "         'patience': 68,\n",
       "         'calmness': 3,\n",
       "         'equanimity': 7,\n",
       "         'acceptance': 60,\n",
       "         'and': 94821,\n",
       "         'compassion': 40,\n",
       "         'developed': 574,\n",
       "         'all': 21911,\n",
       "         'things': 2757,\n",
       "         'buddhism': 95,\n",
       "         'teaches': 36,\n",
       "         'has': 24906,\n",
       "         'very': 5474,\n",
       "         'much': 5135,\n",
       "         'lot': 2629,\n",
       "         'compatible': 14,\n",
       "         'with': 28483,\n",
       "         'christianity': 45,\n",
       "         'especially': 615,\n",
       "         'considering': 231,\n",
       "         'that': 42096,\n",
       "         'sin': 42,\n",
       "         'suffering': 309,\n",
       "         'are': 37981,\n",
       "         'almost': 799,\n",
       "         'same': 6511,\n",
       "         'thing': 3305,\n",
       "         'caused': 153,\n",
       "         'wanting': 88,\n",
       "         'shouldn': 147,\n",
       "         'want': 6650,\n",
       "         'going': 4386,\n",
       "         'about': 13958,\n",
       "         'getting': 2068,\n",
       "         'wrong': 2124,\n",
       "         'way': 4293,\n",
       "         'christian': 221,\n",
       "         'this': 38810,\n",
       "         'would': 8102,\n",
       "         'mean': 1432,\n",
       "         'don': 3050,\n",
       "         'coincide': 8,\n",
       "         'god': 1487,\n",
       "         'will': 35133,\n",
       "         'but': 24718,\n",
       "         'without': 2670,\n",
       "         'aid': 113,\n",
       "         'jesus': 68,\n",
       "         'could': 3266,\n",
       "         'also': 8228,\n",
       "         'seen': 1865,\n",
       "         'proof': 1231,\n",
       "         'mighty': 43,\n",
       "         'omnipotence': 2,\n",
       "         'certainly': 305,\n",
       "         'christians': 185,\n",
       "         'lucky': 175,\n",
       "         'one': 12327,\n",
       "         'such': 5093,\n",
       "         'christ': 27,\n",
       "         'there': 9739,\n",
       "         'side': 1026,\n",
       "         'what': 16859,\n",
       "         'everyone': 2164,\n",
       "         'else': 1658,\n",
       "         'well': 4427,\n",
       "         'many': 5062,\n",
       "         'believe': 2268,\n",
       "         'grace': 70,\n",
       "         'salvation': 10,\n",
       "         'showing': 683,\n",
       "         'upon': 343,\n",
       "         'others': 1610,\n",
       "         'help': 2153,\n",
       "         'study': 230,\n",
       "         'said': 6317,\n",
       "         'see': 6594,\n",
       "         'how': 10232,\n",
       "         'buddha': 183,\n",
       "         'made': 4590,\n",
       "         'similar': 602,\n",
       "         'claims': 605,\n",
       "         'rich': 775,\n",
       "         'man': 3522,\n",
       "         'into': 3509,\n",
       "         'heaven': 72,\n",
       "         'joke': 550,\n",
       "         'basically': 354,\n",
       "         'advocating': 36,\n",
       "         'should': 9259,\n",
       "         'rid': 250,\n",
       "         'ourselves': 117,\n",
       "         'material': 130,\n",
       "         'possessions': 5,\n",
       "         'fact': 1621,\n",
       "         'distinctly': 2,\n",
       "         'remembered': 85,\n",
       "         'making': 2573,\n",
       "         'someone': 1837,\n",
       "         'cry': 365,\n",
       "         'because': 7536,\n",
       "         'asked': 1453,\n",
       "         'achieve': 421,\n",
       "         'replied': 114,\n",
       "         'live': 3152,\n",
       "         'buddhist': 84,\n",
       "         'roughly': 35,\n",
       "         'translated': 32,\n",
       "         'point': 1719,\n",
       "         'out': 8749,\n",
       "         'rarely': 66,\n",
       "         'spoke': 336,\n",
       "         'anything': 2802,\n",
       "         'theory': 194,\n",
       "         'personally': 436,\n",
       "         'knew': 431,\n",
       "         'enough': 1778,\n",
       "         'leave': 873,\n",
       "         'mohamed': 6,\n",
       "         'who': 17586,\n",
       "         'came': 1649,\n",
       "         'later': 554,\n",
       "         'just': 11872,\n",
       "         'remember': 1324,\n",
       "         'conflict': 108,\n",
       "         'difference': 1263,\n",
       "         'opinion': 866,\n",
       "         'education': 922,\n",
       "         'can': 15935,\n",
       "         'fun': 512,\n",
       "         'involving': 58,\n",
       "         'enlightening': 11,\n",
       "         'easier': 164,\n",
       "         'teach': 298,\n",
       "         'something': 2625,\n",
       "         'than': 7355,\n",
       "         'prove': 676,\n",
       "         'right': 4871,\n",
       "         'intelligent': 259,\n",
       "         'design': 86,\n",
       "         'seriously': 641,\n",
       "         'say': 5430,\n",
       "         'first': 4061,\n",
       "         'won': 1354,\n",
       "         'get': 8312,\n",
       "         'its': 10773,\n",
       "         'too': 4291,\n",
       "         'complex': 147,\n",
       "         'normal': 247,\n",
       "         'people': 18385,\n",
       "         'anyway': 402,\n",
       "         'dogmatic': 8,\n",
       "         'then': 7908,\n",
       "         'doesn': 961,\n",
       "         'matter': 1279,\n",
       "         'you': 47345,\n",
       "         'mechante': 1,\n",
       "         'post': 2282,\n",
       "         'any': 9294,\n",
       "         'reason': 1892,\n",
       "         'decide': 540,\n",
       "         'life': 1999,\n",
       "         'move': 854,\n",
       "         'suit': 210,\n",
       "         'identity': 202,\n",
       "         'though': 1264,\n",
       "         'keep': 2553,\n",
       "         'wisdom': 102,\n",
       "         'your': 15283,\n",
       "         'treat': 183,\n",
       "         'went': 1114,\n",
       "         'through': 1819,\n",
       "         'weird': 115,\n",
       "         'hippy': 3,\n",
       "         'phase': 132,\n",
       "         'while': 2860,\n",
       "         'didncha': 1,\n",
       "         'hear': 656,\n",
       "         'end': 1305,\n",
       "         'pro': 725,\n",
       "         'tip': 35,\n",
       "         'put': 1787,\n",
       "         'these': 7138,\n",
       "         'wall': 127,\n",
       "         'jpg': 234,\n",
       "         'learned': 139,\n",
       "         'yours': 272,\n",
       "         'only': 13338,\n",
       "         'different': 1399,\n",
       "         'focus': 524,\n",
       "         'goal': 262,\n",
       "         'not': 37088,\n",
       "         'wrapping': 1,\n",
       "         'paper': 358,\n",
       "         'passed': 257,\n",
       "         'word': 900,\n",
       "         'own': 3054,\n",
       "         'benefit': 591,\n",
       "         'may': 4026,\n",
       "         'read': 2238,\n",
       "         'living': 778,\n",
       "         'thich': 6,\n",
       "         'nhat': 5,\n",
       "         'hanh': 4,\n",
       "         'might': 1476,\n",
       "         'find': 1509,\n",
       "         'subsequent': 30,\n",
       "         'discussions': 80,\n",
       "         'loved': 189,\n",
       "         'ones': 581,\n",
       "         'able': 1316,\n",
       "         'articulate': 27,\n",
       "         'parallels': 18,\n",
       "         'exist': 228,\n",
       "         'between': 1876,\n",
       "         'surprised': 430,\n",
       "         'react': 102,\n",
       "         'negatively': 28,\n",
       "         'having': 1251,\n",
       "         'lost': 1615,\n",
       "         'deserved': 86,\n",
       "         'understanding': 285,\n",
       "         'although': 253,\n",
       "         'indeed': 337,\n",
       "         'display': 106,\n",
       "         'signs': 69,\n",
       "         'being': 4966,\n",
       "         'hurt': 295,\n",
       "         'new': 4771,\n",
       "         'path': 259,\n",
       "         'properly': 206,\n",
       "         'sharing': 219,\n",
       "         'alleviate': 18,\n",
       "         'their': 11870,\n",
       "         'fear': 1084,\n",
       "         'perceive': 18,\n",
       "         'least': 1497,\n",
       "         'alien': 39,\n",
       "         'beliefs': 92,\n",
       "         'allowing': 187,\n",
       "         'long': 2055,\n",
       "         'run': 1257,\n",
       "         'accept': 699,\n",
       "         'necessarily': 66,\n",
       "         'agree': 1204,\n",
       "         'decision': 1093,\n",
       "         'regardless': 90,\n",
       "         'where': 4876,\n",
       "         'make': 6070,\n",
       "         'sit': 333,\n",
       "         'down': 4162,\n",
       "         'together': 766,\n",
       "         'watch': 2205,\n",
       "         'simpsons': 3,\n",
       "         'episode': 160,\n",
       "         'lisa': 4,\n",
       "         'becomes': 745,\n",
       "         'season': 233,\n",
       "         'she': 3036,\n",
       "         'little': 825,\n",
       "         'faith': 454,\n",
       "         'discuss': 190,\n",
       "         'was': 22265,\n",
       "         'teens': 9,\n",
       "         'when': 10161,\n",
       "         'discovered': 116,\n",
       "         'zen': 32,\n",
       "         'meditation': 71,\n",
       "         'undiagnosed': 1,\n",
       "         'bpd': 1,\n",
       "         'homeschooled': 1,\n",
       "         'gotten': 124,\n",
       "         '56k': 3,\n",
       "         'modem': 1,\n",
       "         'web': 219,\n",
       "         'connection': 181,\n",
       "         'across': 957,\n",
       "         'link': 722,\n",
       "         'couple': 280,\n",
       "         'weeks': 355,\n",
       "         'change': 2005,\n",
       "         'palpable': 11,\n",
       "         'felt': 291,\n",
       "         'most': 4018,\n",
       "         'profound': 18,\n",
       "         'sense': 940,\n",
       "         'peace': 771,\n",
       "         'ever': 2134,\n",
       "         'grades': 4,\n",
       "         'immediately': 267,\n",
       "         'started': 1847,\n",
       "         'had': 7164,\n",
       "         'more': 10653,\n",
       "         'energy': 310,\n",
       "         'martial': 22,\n",
       "         'arts': 23,\n",
       "         'huge': 1267,\n",
       "         'positive': 453,\n",
       "         'around': 1527,\n",
       "         'parents': 398,\n",
       "         'fundie': 2,\n",
       "         'changes': 357,\n",
       "         'naiveté': 1,\n",
       "         'kicked': 179,\n",
       "         'foolishly': 25,\n",
       "         'told': 1165,\n",
       "         'been': 7507,\n",
       "         'trying': 2065,\n",
       "         'really': 3299,\n",
       "         'calmed': 4,\n",
       "         'thought': 1384,\n",
       "         'happy': 1479,\n",
       "         'found': 662,\n",
       "         'helped': 414,\n",
       "         'forget': 1120,\n",
       "         'happened': 1669,\n",
       "         'next': 3094,\n",
       "         'mother': 580,\n",
       "         'affected': 139,\n",
       "         'mockingly': 1,\n",
       "         'calm': 151,\n",
       "         'breathy': 1,\n",
       "         'voice': 547,\n",
       "         'pretend': 89,\n",
       "         'content': 325,\n",
       "         'moment': 843,\n",
       "         'belief': 111,\n",
       "         'vanished': 50,\n",
       "         'completely': 662,\n",
       "         'realized': 129,\n",
       "         'probably': 782,\n",
       "         'profoundly': 3,\n",
       "         'sorry': 724,\n",
       "         'did': 8220,\n",
       "         'her': 2676,\n",
       "         'meets': 84,\n",
       "         'jew': 12,\n",
       "         'two': 2177,\n",
       "         'varieties': 5,\n",
       "         'dwell': 7,\n",
       "         'words': 987,\n",
       "         'conservative': 85,\n",
       "         'take': 5280,\n",
       "         'heart': 515,\n",
       "         'spirit': 211,\n",
       "         'teachings': 42,\n",
       "         'hate': 2759,\n",
       "         'oversimplify': 2,\n",
       "         'helps': 188,\n",
       "         'discussing': 142,\n",
       "         'religious': 557,\n",
       "         'letter': 305,\n",
       "         'law': 1034,\n",
       "         'uphill': 13,\n",
       "         'battle': 281,\n",
       "         'wish': 894,\n",
       "         'luck': 334,\n",
       "         'moderates': 12,\n",
       "         'exchange': 124,\n",
       "         'idea': 1143,\n",
       "         'fairly': 69,\n",
       "         'easily': 383,\n",
       "         'comparing': 222,\n",
       "         'contrasting': 6,\n",
       "         'parallel': 47,\n",
       "         'presented': 76,\n",
       "         'differently': 55,\n",
       "         'wouldn': 229,\n",
       "         'ordinary': 142,\n",
       "         'give': 5995,\n",
       "         'relevant': 187,\n",
       "         'spiritual': 54,\n",
       "         'advice': 233,\n",
       "         'even': 9240,\n",
       "         'believer': 25,\n",
       "         'religion': 980,\n",
       "         'dont': 8012,\n",
       "         'worry': 790,\n",
       "         'yourself': 687,\n",
       "         'meditate': 15,\n",
       "         'regularly': 92,\n",
       "         'try': 1465,\n",
       "         'hard': 1832,\n",
       "         'aware': 523,\n",
       "         'everything': 2132,\n",
       "         'follow': 1064,\n",
       "         'coming': 1760,\n",
       "         'throught': 1,\n",
       "         'his': 19478,\n",
       "         'situation': 745,\n",
       "         'welcome': 453,\n",
       "         'pms': 368,\n",
       "         'recently': 372,\n",
       "         'bible': 19,\n",
       "         'belt': 109,\n",
       "         'whole': 1673,\n",
       "         'ordeal': 10,\n",
       "         'involved': 488,\n",
       "         'leaving': 207,\n",
       "         'baptist': 4,\n",
       "         'church': 83,\n",
       "         'pretty': 710,\n",
       "         'rough': 32,\n",
       "         'those': 3443,\n",
       "         'care': 1258,\n",
       "         'open': 1027,\n",
       "         'accepting': 149,\n",
       "         'good': 8049,\n",
       "         'created': 1090,\n",
       "         'relationships': 29,\n",
       "         'handful': 38,\n",
       "         'lovely': 70,\n",
       "         'conversations': 33,\n",
       "         'truly': 397,\n",
       "         'respect': 1292,\n",
       "         'suggested': 76,\n",
       "         'great': 4015,\n",
       "         'important': 1522,\n",
       "         'dialogue': 115,\n",
       "         'buddhists': 29,\n",
       "         'message': 1033,\n",
       "         'unto': 7,\n",
       "         'start': 1730,\n",
       "         'understand': 2366,\n",
       "         'control': 606,\n",
       "         'always': 3076,\n",
       "         'subject': 204,\n",
       "         'better': 3906,\n",
       "         'understood': 207,\n",
       "         'learning': 163,\n",
       "         'vocabulary': 23,\n",
       "         'means': 1485,\n",
       "         'praise': 414,\n",
       "         'worship': 109,\n",
       "         'guy': 1549,\n",
       "         'named': 298,\n",
       "         'due': 1875,\n",
       "         'let': 2903,\n",
       "         'know': 7728,\n",
       "         'both': 2347,\n",
       "         'messages': 130,\n",
       "         'philosophy': 55,\n",
       "         'became': 948,\n",
       "         'enlightened': 38,\n",
       "         'become': 3105,\n",
       "         'annointed': 1,\n",
       "         'continue': 791,\n",
       "         'practice': 212,\n",
       "         'work': 4818,\n",
       "         'issues': 1583,\n",
       "         'best': 3905,\n",
       "         'heard': 799,\n",
       "         'question': 2378,\n",
       "         'person': 2562,\n",
       "         'introduce': 62,\n",
       "         'challenges': 130,\n",
       "         'coping': 3,\n",
       "         'problems': 627,\n",
       "         'answer': 1303,\n",
       "         'lama': 26,\n",
       "         'quite': 688,\n",
       "         'interesting': 441,\n",
       "         'instead': 1649,\n",
       "         'giving': 2298,\n",
       "         'maybe': 832,\n",
       "         'ask': 2741,\n",
       "         'think': 6383,\n",
       "         'must': 3072,\n",
       "         'excited': 131,\n",
       "         'dharma': 98,\n",
       "         'books': 194,\n",
       "         'house': 634,\n",
       "         'sure': 2355,\n",
       "         'pick': 294,\n",
       "         'quick': 197,\n",
       "         'browse': 13,\n",
       "         'looking': 871,\n",
       "         'learn': 669,\n",
       "         'bit': 558,\n",
       "         'other': 6319,\n",
       "         'traditions': 48,\n",
       "         'browsing': 7,\n",
       "         'owned': 138,\n",
       "         'times': 2104,\n",
       "         'cultures': 22,\n",
       "         'were': 6481,\n",
       "         'beginning': 204,\n",
       "         'nor': 680,\n",
       "         'mind': 1317,\n",
       "         'born': 438,\n",
       "         'died': 331,\n",
       "         'replace': 196,\n",
       "         'prayer': 29,\n",
       "         'couting': 1,\n",
       "         'breath': 112,\n",
       "         'name': 2805,\n",
       "         'happydoes': 1,\n",
       "         'evil': 312,\n",
       "         'include': 171,\n",
       "         'lady': 282,\n",
       "         'pai': 36,\n",
       "         'chunked': 1,\n",
       "         'our': 12719,\n",
       "         'campaign': 2437,\n",
       "         'suns': 3,\n",
       "         'pelor': 5,\n",
       "         'shamedan': 3,\n",
       "         'stifling': 8,\n",
       "         'sun': 208,\n",
       "         'desert': 29,\n",
       "         'burning': 171,\n",
       "         'kill': 640,\n",
       "         'mercy': 85,\n",
       "         'second': 1096,\n",
       "         'brings': 157,\n",
       "         'drought': 17,\n",
       "         'fire': 382,\n",
       "         'destroys': 59,\n",
       "         'generally': 122,\n",
       "         'nice': 623,\n",
       "         'race': 209,\n",
       "         'fey': 3,\n",
       "         'called': 2125,\n",
       "         'hags': 1,\n",
       "         'him': 9536,\n",
       "         'radiant': 1,\n",
       "         'resistance': 33,\n",
       "         'haven': 198,\n",
       "         'played': 353,\n",
       "         'nearly': 184,\n",
       "         'part': 1679,\n",
       "         'technically': 58,\n",
       "         'argue': 135,\n",
       "         'sobek': 1,\n",
       "         'represent': 203,\n",
       "         'power': 6158,\n",
       "         'crocodiles': 8,\n",
       "         'whereas': 302,\n",
       "         'represents': 98,\n",
       "         'fertile': 8,\n",
       "         'land': 961,\n",
       "         'shapeshift': 1,\n",
       "         'crocodile': 30,\n",
       "         'badass': 21,\n",
       "         'zarus': 1,\n",
       "         'blood': 312,\n",
       "         'souls': 70,\n",
       "         'lord': 242,\n",
       "         'arioch': 1,\n",
       "         'liked': 148,\n",
       "         'vecna': 1,\n",
       "         'use': 2169,\n",
       "         'story': 958,\n",
       "         'blast': 106,\n",
       "         'playing': 697,\n",
       "         'far': 1491,\n",
       "         'powerful': 557,\n",
       "         'deity': 22,\n",
       "         'dangerous': 442,\n",
       "         'portfolio': 53,\n",
       "         'favorite': 143,\n",
       "         'pale': 9,\n",
       "         'night': 404,\n",
       "         'close': 526,\n",
       "         'guess': 714,\n",
       "         'abyssal': 1,\n",
       "         'lords': 9,\n",
       "         'rulers': 46,\n",
       "         'nine': 38,\n",
       "         'hells': 4,\n",
       "         'straightforward': 18,\n",
       "         'ample': 26,\n",
       "         'backstory': 1,\n",
       "         'lack': 577,\n",
       "         'thereof': 12,\n",
       "         'intriguing': 12,\n",
       "         'suggestions': 142,\n",
       "         'additional': 86,\n",
       "         'deities': 9,\n",
       "         'overlap': 7,\n",
       "         'cavern': 1,\n",
       "         'dwelling': 5,\n",
       "         'gnolls': 2,\n",
       "         'consider': 423,\n",
       "         'blinding': 11,\n",
       "         'wicked': 16,\n",
       "         'light': 343,\n",
       "         'loki': 30,\n",
       "         'sufficiently': 15,\n",
       "         'fooled': 231,\n",
       "         'over': 4407,\n",
       "         'years': 8003,\n",
       "         'thinking': 956,\n",
       "         'benefactor': 6,\n",
       "         'leading': 340,\n",
       "         'bountiful': 1,\n",
       "         'crops': 37,\n",
       "         'steal': 120,\n",
       "         'peasantry': 2,\n",
       "         'statues': 116,\n",
       "         'fat': 81,\n",
       "         'woman': 376,\n",
       "         'food': 634,\n",
       "         'starving': 25,\n",
       "         'view': 546,\n",
       "         'death': 651,\n",
       "         'justice': 495,\n",
       "         'righteous': 18,\n",
       "         'served': 219,\n",
       "         'brutal': 66,\n",
       "         'conflicts': 21,\n",
       "         'cliche': 3,\n",
       "         'cyric': 1,\n",
       "         'mortal': 14,\n",
       "         'nabbed': 3,\n",
       "         'got': 3549,\n",
       "         'chance': 987,\n",
       "         'gotta': 91,\n",
       "         'zon': 2,\n",
       "         'kuthon': 1,\n",
       "         'sister': 200,\n",
       "         'shelyn': 1,\n",
       "         'cool': 262,\n",
       "         'pathfinder': 3,\n",
       "         'setting': 180,\n",
       "         'plus': 366,\n",
       "         'off': 1912,\n",
       "         'topic': 292,\n",
       "         'coolest': 11,\n",
       "         'cayden': 1,\n",
       "         'cailean': 1,\n",
       "         'bard': 3,\n",
       "         'wasted': 174,\n",
       "         'stumbled': 9,\n",
       "         'temple': 441,\n",
       "         'star': 359,\n",
       "         'stone': 182,\n",
       "         'artifact': 5,\n",
       "         'turn': 672,\n",
       "         'woke': 61,\n",
       "         'morning': 386,\n",
       "         'hangover': 10,\n",
       "         'memory': 114,\n",
       "         'before': 4257,\n",
       "         'godly': 4,\n",
       "         'powers': 251,\n",
       "         'homebrew': 1,\n",
       "         'primary': 134,\n",
       "         'lawful': 5,\n",
       "         'friend': 647,\n",
       "         'lewie': 1,\n",
       "         'essentially': 52,\n",
       "         'three': 659,\n",
       "         'domains': 7,\n",
       "         'tyranny': 21,\n",
       "         'applied': 84,\n",
       "         'vengeance': 12,\n",
       "         'community': 686,\n",
       "         'cruel': 45,\n",
       "         'harsh': 75,\n",
       "         'recognizes': 8,\n",
       "         'catch': 183,\n",
       "         'flies': 19,\n",
       "         'honey': 20,\n",
       "         'vinegar': 2,\n",
       "         'thus': 263,\n",
       "         'often': 291,\n",
       "         'benevolent': 9,\n",
       "         'toward': 66,\n",
       "         'common': 1438,\n",
       "         'day': 3560,\n",
       "         'basis': 374,\n",
       "         'running': 732,\n",
       "         'gag': 8,\n",
       "         'lewian': 1,\n",
       "         'churches': 51,\n",
       "         'sponsor': 23,\n",
       "         'inner': 51,\n",
       "         'city': 530,\n",
       "         'basketball': 5,\n",
       "         'teams': 99,\n",
       "         'major': 893,\n",
       "         'dynamic': 201,\n",
       "         'within': 891,\n",
       "         'shall': 334,\n",
       "         'lump': 10,\n",
       "         'wherever': 137,\n",
       "         'lumps': 4,\n",
       "         'warts': 2,\n",
       "         'tree': 78,\n",
       "         'burls': 1,\n",
       "         'breasts': 3,\n",
       "         'humpback': 1,\n",
       "         'whales': 2,\n",
       "         'snatched': 63,\n",
       "         'chaos': 90,\n",
       "         'nurgle': 1,\n",
       "         'plague': 21,\n",
       "         'whfb': 1,\n",
       "         'wh40k': 1,\n",
       "         'universe': 77,\n",
       "         'renamed': 81,\n",
       "         'narghull': 1,\n",
       "         'nar': 5,\n",
       "         'ghull': 1,\n",
       "         'random': 163,\n",
       "         'apostrophes': 2,\n",
       "         'revolved': 5,\n",
       "         'cult': 84,\n",
       "         'wake': 242,\n",
       "         'sleep': 240,\n",
       "         'lasted': 19,\n",
       "         '1000': 316,\n",
       "         'sadly': 159,\n",
       "         'stalled': 51,\n",
       "         'lazy': 122,\n",
       "         'back': 5073,\n",
       "         'meant': 303,\n",
       "         'encountered': 15,\n",
       "         'directly': 521,\n",
       "         'meaning': 250,\n",
       "         'worked': 575,\n",
       "         'stats': 88,\n",
       "         'works': 837,\n",
       "         'spread': 581,\n",
       "         'diseases': 17,\n",
       "         'damn': 378,\n",
       "         'demogorgon': 1,\n",
       "         'fuck': 987,\n",
       "         'shit': 1437,\n",
       "         'badasss': 1,\n",
       "         'gods': 136,\n",
       "         'real': 2363,\n",
       "         'choose': 634,\n",
       "         'list': 994,\n",
       "         'plenty': 117,\n",
       "         'cthulhu': 2,\n",
       "         'mythos': 2,\n",
       "         'fyi': 87,\n",
       "         'traditional': 85,\n",
       "         'chtonic': 1,\n",
       "         'magic': 177,\n",
       "         'romans': 5,\n",
       "         'goddess': 19,\n",
       "         'hecate': 1,\n",
       "         'goes': 1656,\n",
       "         'big': 2869,\n",
       "         'fan': 688,\n",
       "         'shar': 6,\n",
       "         'forgotten': 192,\n",
       "         'realms': 10,\n",
       "         'ultimate': 87,\n",
       "         'despair': 9,\n",
       "         'loss': 472,\n",
       "         'followers': 475,\n",
       "         'bother': 164,\n",
       "         'asking': 1424,\n",
       "         'small': 889,\n",
       "         'boons': 1,\n",
       "         'invoke': 22,\n",
       "         'themselves': 751,\n",
       "         'hopes': 119,\n",
       "         'events': 195,\n",
       "         'prevent': 138,\n",
       "         'needing': 16,\n",
       "         'bringing': 404,\n",
       "         'world': 4207,\n",
       "         'isn': 589,\n",
       "         'pansy': 2,\n",
       "         'goddesses': 3,\n",
       "         'nod': 221,\n",
       "         'appreciation': 72,\n",
       "         'sacrifice': 102,\n",
       "         'somebody': 202,\n",
       "         'near': 405,\n",
       "         'nothing': 3187,\n",
       "         'check': 997,\n",
       "         'dogma': 9,\n",
       "         'here': 4357,\n",
       "         'prometheus': 4,\n",
       "         'pcs': 15,\n",
       "         'however': 701,\n",
       "         'demi': 8,\n",
       "         'why': 11742,\n",
       "         'gives': 1047,\n",
       "         'mortals': 20,\n",
       "         'jealous': 161,\n",
       "         'granted': 158,\n",
       "         'half': 592,\n",
       "         'status': 462,\n",
       "         'creation': 231,\n",
       "         'revenge': 162,\n",
       "         'humanity': 169,\n",
       "         'order': 792,\n",
       "         'tides': 1,\n",
       "         'among': 738,\n",
       "         'furthermore': 14,\n",
       "         'perhaps': 281,\n",
       "         'repercussion': 6,\n",
       "         'feels': 294,\n",
       "         'action': 1229,\n",
       "         'dragged': 53,\n",
       "         'underworld': 10,\n",
       "         'cerberus': 1,\n",
       "         'seem': 556,\n",
       "         'less': 1179,\n",
       "         'inhuman': 25,\n",
       "         'face': 1475,\n",
       "         'judgment': 35,\n",
       "         'egyptian': 1,\n",
       "         'morals': 21,\n",
       "         'virtue': 24,\n",
       "         'judge': 441,\n",
       "         'dead': 499,\n",
       "         'hextor': 1,\n",
       "         'boss': 291,\n",
       "         'conquest': 6,\n",
       "         'lawyers': 74,\n",
       "         'wee': 9,\n",
       "         'jas': 4,\n",
       "         'neutral': 290,\n",
       "         'necromancy': 1,\n",
       "         'perfect': 356,\n",
       "         'representation': 49,\n",
       "         'inevitable': 48,\n",
       "         'which': 8656,\n",
       "         'plans': 360,\n",
       "         'thwarted': 7,\n",
       "         'merely': 114,\n",
       "         'waits': 10,\n",
       "         'cleric': 10,\n",
       "         'fabulous': 33,\n",
       "         'master': 494,\n",
       "         'bassui': 1,\n",
       "         'functioning': 63,\n",
       "         'analytical': 13,\n",
       "         'consciousness': 35,\n",
       "         'destroyed': 852,\n",
       "         'feelings': 110,\n",
       "         'purified': 6,\n",
       "         'referred': 61,\n",
       "         'pure': 382,\n",
       "         'west': 493,\n",
       "         'physical': 82,\n",
       "         'body': 500,\n",
       "         'inception': 23,\n",
       "         'true': 2098,\n",
       "         'rather': 943,\n",
       "         'temporary': 50,\n",
       "         'formation': 50,\n",
       "         'five': 1008,\n",
       "         'aggregates': 2,\n",
       "         'after': 7643,\n",
       "         'four': 328,\n",
       "         'elements': 145,\n",
       "         'disperse': 5,\n",
       "         'remains': 259,\n",
       "         'self': 957,\n",
       "         'originally': 16,\n",
       "         'empty': 274,\n",
       "         'seeks': 124,\n",
       "         'bliss': 16,\n",
       "         'extinguish': 2,\n",
       "         'seeking': 266,\n",
       "         'thoughts': 307,\n",
       "         'attachment': 26,\n",
       "         'form': 780,\n",
       "         'consisting': 8,\n",
       "         'individual': 261,\n",
       "         'nature': 188,\n",
       "         'aspect': 92,\n",
       "         'disorder': 18,\n",
       "         'opposed': 297,\n",
       "         'usual': 296,\n",
       "         'taught': 179,\n",
       "         'schools': 150,\n",
       "         'now': 12934,\n",
       "         'dimension': 14,\n",
       "         'afterlife': 2,\n",
       "         'flavours': 3,\n",
       "         'ideas': 336,\n",
       "         'realize': 288,\n",
       "         'compared': 417,\n",
       "         'abrahamic': 25,\n",
       "         'religions': 160,\n",
       "         'bunch': 262,\n",
       "         'taken': 1635,\n",
       "         'literally': 418,\n",
       "         'non': 1196,\n",
       "         'sinner': 3,\n",
       "         'whatever': 928,\n",
       "         'useless': 348,\n",
       "         'historical': 115,\n",
       "         'himself': 1599,\n",
       "         'dramatically': 21,\n",
       "         'styles': 11,\n",
       "         'audience': 171,\n",
       "         'parables': 2,\n",
       "         'metaphors': 4,\n",
       "         'believing': 110,\n",
       "         'physically': 42,\n",
       "         'koans': 5,\n",
       "         'example': 663,\n",
       "         'purely': 95,\n",
       "         'distilled': 1,\n",
       "         'stories': 235,\n",
       "         'reading': 392,\n",
       "         'history': 1201,\n",
       "         'book': 485,\n",
       "         'entirely': 117,\n",
       "         'irrelevant': 128,\n",
       "         'does': 4001,\n",
       "         'wondering': 182,\n",
       "         'happen': 1257,\n",
       "         'place': 1487,\n",
       "         'missing': 352,\n",
       "         'worth': 611,\n",
       "         'noting': 25,\n",
       "         'psychological': 22,\n",
       "         'phenomenon': 42,\n",
       "         'makes': 1346,\n",
       "         'cosmology': 2,\n",
       "         'competitor': 16,\n",
       "         'cosmos': 4,\n",
       "         'comment': 784,\n",
       "         'simply': 568,\n",
       "         'gets': 1217,\n",
       "         'metaphysical': 1,\n",
       "         'supernatural': 4,\n",
       "         'hope': 2204,\n",
       "         'maintain': 143,\n",
       "         'exists': 120,\n",
       "         'beyond': 449,\n",
       "         'exercised': 4,\n",
       "         'mara': 31,\n",
       "         'samsara': 7,\n",
       "         'worlds': 242,\n",
       "         'planes': 120,\n",
       "         'dimensions': 7,\n",
       "         'experience': 362,\n",
       "         'joy': 89,\n",
       "         'sadness': 9,\n",
       "         'love': 2367,\n",
       "         'heartbreaks': 1,\n",
       "         'etc': 2159,\n",
       "         'done': 5459,\n",
       "         'streams': 19,\n",
       "         'began': 134,\n",
       "         'attracted': 29,\n",
       "         'begin': 210,\n",
       "         'develop': 323,\n",
       "         'craving': 9,\n",
       "         'existence': 179,\n",
       "         'begins': 163,\n",
       "         'cycle': 97,\n",
       "         'rebirth': 29,\n",
       "         'lands': 73,\n",
       "         'amitabha': 32,\n",
       "         'individuals': 141,\n",
       "         'attain': 43,\n",
       "         'enlightenment': 35,\n",
       "         'pace': 152,\n",
       "         'attraction': 19,\n",
       "         'emotions': 80,\n",
       "         'sex': 140,\n",
       "         'overwhelming': 42,\n",
       "         'overcome': 53,\n",
       "         'lifetime': 73,\n",
       "         '100': 1242,\n",
       "         'average': 328,\n",
       "         'human': 546,\n",
       "         'beings': 66,\n",
       "         'shorter': 15,\n",
       "         'yet': 1229,\n",
       "         'longer': 271,\n",
       "         'refuge': 44,\n",
       "         ...})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int = {word : i + 1 for i, (word, count) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/vocab_to_int\", vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode comments\n",
    "comments_int = []\n",
    "for comment in comments:\n",
    "    try:\n",
    "        result = [vocab_to_int[word] for word in comment.split(\" \")]\n",
    "    except:\n",
    "        pass\n",
    "    comments_int.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels (-1 = NEGATIVE; 0 = NEUTRAL; 1 = POSITIVE)\n",
    "ys = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reddit_df)):\n",
    "    ys.append(int(reddit_df.iloc[i][1]))\n",
    "\n",
    "for i in range(len(twitter_df)):\n",
    "    ys.append(int(twitter_df.iloc[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, -1, 0, 1, -1, 1, 0, -1, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If comments are shorted than a given sequence\n",
    "# length, pad with zeros\n",
    "# If comments are longer than a given sequence\n",
    "# length, truncate them\n",
    "def pad_features(comments_int, seq_length):\n",
    "    # xs = Matrix(len(comments_int) X seq_length)\n",
    "    xs = np.zeros((len(comments_int), seq_length), dtype = int)\n",
    "    \n",
    "    # For each indexed comment\n",
    "    for i, comment in enumerate(comments_int):\n",
    "        comment_len = len(comment)\n",
    "        \n",
    "        # If the comment length is <= the sequence length\n",
    "        if comment_len <= seq_length:\n",
    "            # Pad with zeros\n",
    "            zeros = list(np.zeros(seq_length - comment_len))\n",
    "            new = zeros + comment\n",
    "        \n",
    "        # Otherwise, truncate\n",
    "        elif comment_len > seq_length:\n",
    "            new = comment[0:seq_length]\n",
    "            \n",
    "        # Populate the features array\n",
    "        xs[i][:] = np.array(new)\n",
    "        \n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 250\n",
    "xs = pad_features(comments_int, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_percentage = 0.7\n",
    "x_train = xs[0 : int(split_percentage * len(xs))]\n",
    "y_train = ys[0 : int(split_percentage * len(ys))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_xs = xs[int(split_percentage * len(xs)):]\n",
    "remaining_ys = ys[int(split_percentage * len(ys)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = remaining_xs[0 : int(len(remaining_xs) * 0.5)]\n",
    "y_valid = remaining_ys[0 : int(len(remaining_ys) * 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = remaining_xs[int(len(remaining_xs) * 0.5):]\n",
    "y_test = remaining_ys[int(len(remaining_ys) * 0.5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataloaders ready for training and testing\n",
    "train_data = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(x_valid), torch.from_numpy(y_valid))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, shuffle = True, batch_size = BS)\n",
    "valid_loader = DataLoader(valid_data, shuffle = True, batch_size = BS)\n",
    "test_loader = DataLoader(test_data, shuffle = True, batch_size = BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "class SentimentAnalyzer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        output_size,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        n_layers\n",
    "    ):\n",
    "        super(SentimentAnalyzer, self).__init__()\n",
    "        \n",
    "        # Output layer size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Number of LSTM layers\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Hidden layer dimension of LSTM cell\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = -1)\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            n_layers,\n",
    "            dropout = 0.5,\n",
    "            batch_first = True\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \n",
    "        # Xs are going to be of size BATCH_SIZE x SEQ_LEN\n",
    "        # We are interested in the batch size, so x.size(0)\n",
    "        # will give us that\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Output from the embedding layer\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        # Output and new hidden layer from\n",
    "        # LSTM layer\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        # We'll convert that LSTM output into a contiguous\n",
    "        # tensor. This prevents certain runtime errors\n",
    "        # from occuring when certain operations happen\n",
    "        # (like getting a view of a transposed tensor)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # Output after dropping some neurons with\n",
    "        # 30% dropout rate\n",
    "        out = F.dropout(lstm_out, 0.3)\n",
    "        \n",
    "        # Output of fully connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # Our labels are -1, 0 and 1\n",
    "        # Tanh(x) belongs to the interval [-1, 1]\n",
    "        tanh_out = F.tanh(out)\n",
    "        tanh_out = tanh_out.view(batch_size, -1)\n",
    "        tanh_out = tanh_out[:,-1]\n",
    "        \n",
    "        return tanh_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(), \n",
    "                 weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentAnalyzer(\n",
      "  (embedding): Embedding(218602, 400, padding_idx=218601)\n",
      "  (lstm): LSTM(400, 32, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and hyperparams\n",
    "vocab_size = len(vocab_to_int) + 1\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentAnalyzer(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "model = model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-761a64b8c052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "cnt = 0\n",
    "print_every = 100\n",
    "gradient_clip = 5\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    # Initialize hidden state with \n",
    "    # initial model weights and biases\n",
    "    # Needed because LSTMs are recurrent networks,\n",
    "    # Meaning that each output produces a new\n",
    "    # hidden state, which will be passed though a\n",
    "    # new cell / layer, which will repeat the process.\n",
    "    hidden_state = model.init_hidden(BS)\n",
    "    \n",
    "    # Loop on batch\n",
    "    for x, y in train_loader:\n",
    "        cnt += 1\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        hidden_state = tuple([state.data for state in hidden_state])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        x = x.type(torch.LongTensor)\n",
    "        x = x.cuda()\n",
    "        out, hidden_state = model(x, hidden_state)\n",
    "        loss = F.binary_cross_entropy(out.squeeze(), y.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        # RNNs and LSTMs have an issue where the gradient will\n",
    "        # explode A.K.A they will get so big or so small, to\n",
    "        # the point where they will overflow the data type's allocated\n",
    "        # (e.g. the would get over the max integer value - 2,147,483,647 - if the gradient\n",
    "        # was an integer)\n",
    "        # PyTorch has a nice util called \"clip_grad_norm\" which can help\n",
    "        # prevent this issue\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (cnt - 1) % print_every == 0:\n",
    "            # Get validation loss\n",
    "            # Same spiel as above, except this is for validation\n",
    "            val_h_s = model.init_hidden(BS)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for x_val, y_val in valid_loader:\n",
    "                val_h_s = tuple([state.data for state in val_h_s])\n",
    "                \n",
    "                x_val, y_val = x_val.cuda(), y_val.cuda()\n",
    "                \n",
    "                x_val = x_val.type(torch.LongTensor)\n",
    "                out, val_h_s = model(x_val, val_h_s)\n",
    "                val_loss = F.binary_cross_entropy_with_logits(out.cpu().squeeze(), y_val.cpu().float())\n",
    "                \n",
    "                val_losses.append(val_loss.item())\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "            print(f\"Epoch: {epoch + 1}/{epochs}\",\n",
    "                  f\"Step: {cnt}\",\n",
    "                  f\"Loss: {loss.item():.6f}\",\n",
    "                  f\"Val Loss: {np.mean(val_losses):.6f}\",\n",
    "                   \"Saving...\")\n",
    "            torch.save(model, \"../models/SentimentAnalyzer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bit93e3f1eb3f6e4d4bafd0e7f31c734b86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
